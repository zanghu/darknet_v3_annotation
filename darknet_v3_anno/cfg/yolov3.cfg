[net]
# Testing
# batch=1
# subdivisions=1
# Training
batch=64
subdivisions=16
width=608
height=608
channels=3
momentum=0.9
decay=0.0005
angle=0
saturation = 1.5
exposure = 1.5
hue=.1

learning_rate=0.001
burn_in=1000
max_batches = 500200
policy=steps
steps=400000,450000
scales=.1,.1

# 包含各类型层个数:
# yolo: 3
# convolutional: 75
# route: 4
# upsample: 2
# shortcut: 23
# 合计: 107

# 001
[convolutional]
batch_normalize=1
filters=32
size=3
stride=1
pad=1
activation=leaky

# Downsample

# 002
[convolutional]
batch_normalize=1
filters=64
size=3
stride=2
pad=1
activation=leaky

# 003
[convolutional]
batch_normalize=1
filters=32
size=1
stride=1
pad=1
activation=leaky

# 004
[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=leaky

# 005
[shortcut]
from=-3 # 索引号是相对于当前层索引号的offset值, 并不是相对于network对象最后一层的index
activation=linear

# Downsample

# 006
[convolutional]
batch_normalize=1
filters=128
size=3
stride=2
pad=1
activation=leaky

# 007
[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=leaky

# 008
[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky

# 009
[shortcut]
from=-3
activation=linear

# 010
[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=leaky

# 011
[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky

# 012
[shortcut]
from=-3
activation=linear

# Downsample

# 013
[convolutional]
batch_normalize=1
filters=256
size=3
stride=2
pad=1
activation=leaky

# 014
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

# 015
[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

# 016
[shortcut]
from=-3
activation=linear

# 017
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

# 018
[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

# 019
[shortcut]
from=-3
activation=linear

# 020
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

# 021
[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

# 022
[shortcut]
from=-3
activation=linear

# 023
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

# 024
[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

# 025
[shortcut]
from=-3
activation=linear

# 026
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

# 027
[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

# 028
[shortcut]
from=-3
activation=linear

# 029
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

# 030
[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

# 031
[shortcut]
from=-3
activation=linear

# 032
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

# 033
[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

# 034
[shortcut]
from=-3
activation=linear

# 035
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

# 036
[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

# 037
[shortcut]
from=-3
activation=linear

# Downsample

# 038
[convolutional]
batch_normalize=1
filters=512
size=3
stride=2
pad=1
activation=leaky

# 039
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

# 040
[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

# 041
[shortcut]
from=-3
activation=linear

# 042
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

# 043
[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

# 044
[shortcut]
from=-3
activation=linear

# 045
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

# 046
[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

# 047
[shortcut]
from=-3
activation=linear

# 048
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

# 049
[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

# 050
[shortcut]
from=-3
activation=linear

# 051
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

# 052
[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

# 053
[shortcut]
from=-3
activation=linear

# 054
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

# 055
[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

# 056
[shortcut]
from=-3
activation=linear

# 057
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

# 058
[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

# 059
[shortcut]
from=-3
activation=linear

# 060
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

# 061
[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

# 062
[shortcut]
from=-3
activation=linear

# Downsample

# 063
[convolutional]
batch_normalize=1
filters=1024
size=3
stride=2
pad=1
activation=leaky

# 064
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

# 065
[convolutional]
batch_normalize=1
filters=1024
size=3
stride=1
pad=1
activation=leaky

# 066
[shortcut]
from=-3
activation=linear

# 067
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

# 068
[convolutional]
batch_normalize=1
filters=1024
size=3
stride=1
pad=1
activation=leaky

# 069
[shortcut]
from=-3
activation=linear

# 070
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

# 071
[convolutional]
batch_normalize=1
filters=1024
size=3
stride=1
pad=1
activation=leaky

# 072
[shortcut]
from=-3
activation=linear

# 073
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

# 074
[convolutional]
batch_normalize=1
filters=1024
size=3
stride=1
pad=1
activation=leaky

# 075
[shortcut]
from=-3
activation=linear

######################

# 076
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

# 077
[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=1024
activation=leaky

# 078
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

# 079
[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=1024
activation=leaky

# 080
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

# 081
[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=1024
activation=leaky

# 082
[convolutional]
size=1
stride=1
pad=1
filters=255
activation=linear

# 083
[yolo]
mask = 6,7,8
anchors = 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326
classes=80
num=9
jitter=.3
ignore_thresh = .7
truth_thresh = 1
random=1

# 084
[route]
layers = -4

# 085
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

# 086
[upsample]
stride=2

# 087
[route]
layers = -1, 61

# 088
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

# 089
[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=512
activation=leaky

# 090
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

# 091
[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=512
activation=leaky

# 092
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

# 093
[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=512
activation=leaky

# 094
[convolutional]
size=1
stride=1
pad=1
filters=255
activation=linear

# 095
[yolo]
mask = 3,4,5
anchors = 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326
classes=80
num=9
jitter=.3
ignore_thresh = .7
truth_thresh = 1
random=1

# 096
[route]
layers = -4

# 097
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

# 098
[upsample]
stride=2

# 099
[route]
layers = -1, 36

# 100
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

# 101
[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=256
activation=leaky

# 102
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

# 103
[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=256
activation=leaky

# 104
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

# 105
[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=256
activation=leaky

# 106
[convolutional]
size=1
stride=1
pad=1
filters=255 # 猜测: 每次使用[yolo]中的3个anchor, 相当于每点处生成3个标定框, coco数据集有80分类
            #      所以输出向量计算公式是: ((4 + 1) + 80) * 3 = 255, 其中4表示bbox四个坐标, 1是置信度, 80是coco数据集类标数, 3是每点处的三个预测bbox
activation=linear

# 107
[yolo]
mask = 0,1,2
anchors = 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326
classes=80
num=9 # 实际指明的是l.total属性, 保持与anchors中候选框的个数一致(从代码的角度分析, 小于等于anchors候选框个数即可保证不会出现内存越界). 这个项其实可以从anchors中直接计算出, 似乎是多余的
jitter=.3
ignore_thresh = .7
truth_thresh = 1
random=1

